# ============================================
# app.py  (FULL + Free AI on HF, Spaces-ready)
# FactoryRAG-TAF ‚Äî Chat & Expert Evaluation
# with Result Explanation (Rule-based TH/EN) + (Optional) Free AI via HuggingFace
# ============================================

# ---------- Hugging Face Spaces: fix write/caching perms ----------
import os
from pathlib import Path

RUNTIME_DIR = "/tmp/.streamlit"
Path(RUNTIME_DIR).mkdir(parents=True, exist_ok=True)
os.environ["HOME"] = "/tmp"
os.environ["XDG_CACHE_HOME"] = RUNTIME_DIR
os.environ["XDG_CONFIG_HOME"] = RUNTIME_DIR
os.environ["XDG_STATE_HOME"] = RUNTIME_DIR
os.environ["STREAMLIT_CACHE_DIR"] = os.path.join(RUNTIME_DIR, "cache")
os.environ["HF_HOME"] = "/tmp"          # HF cache
os.environ["TRANSFORMERS_CACHE"] = "/tmp"

# =====================================
# Fix Streamlit PermissionError on Hugging Face
# =====================================
import os
from pathlib import Path

TMP_DIR = "/tmp/streamlit_fix"
Path(TMP_DIR).mkdir(parents=True, exist_ok=True)
os.environ["STREAMLIT_HOME"] = TMP_DIR
os.environ["STREAMLIT_CACHE_DIR"] = os.path.join(TMP_DIR, "cache")
os.environ["XDG_CONFIG_HOME"] = TMP_DIR
os.environ["XDG_CACHE_HOME"] = TMP_DIR
os.environ["XDG_STATE_HOME"] = TMP_DIR
os.environ["HOME"] = TMP_DIR

cfg_path = Path(TMP_DIR) / "config.toml"
if not cfg_path.exists():
    with open(cfg_path, "w") as f:
        f.write("[server]\nheadless = true\nport = 8501\n")

# =====================================
# Now safe to import streamlit
# =====================================
import streamlit as st
import pandas as pd
import numpy as np
import json, re, math, hashlib, time, textwrap
from collections import Counter
from datetime import datetime

os.environ.setdefault("HOME", "/app")
os.environ.setdefault("STREAMLIT_BROWSER_GATHERUSAGESTATS", "false")
os.environ.setdefault("STREAMLIT_CONFIG_DIR", "/app/.streamlit")
Path("./.streamlit").mkdir(parents=True, exist_ok=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="FactoryRAG-TAF Chat + Expert Eval", layout="wide")
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# -----------------------------
# CONFIG paths
# -----------------------------
PATH_CMMS   = Path("cmms_logs.csv")
PATH_SENSOR = Path("sensor_features.csv")
PATH_MAN    = Path("manual_index.json")
PATH_Q      = Path("queries.csv")  # optional
PATH_WEIGHTS = Path("task_aware_best_weights.json")
LOG_PATH = Path("expert_chat_logs.csv")

# -----------------------------
# LOAD DATA (cached)
# -----------------------------
@st.cache_data(show_spinner=False)
def load_all():
    cmms = pd.read_csv(PATH_CMMS) if PATH_CMMS.exists() else pd.DataFrame()
    sensor = pd.read_csv(PATH_SENSOR) if PATH_SENSOR.exists() else pd.DataFrame()
    manuals = []
    if PATH_MAN.exists():
        try:
            with open(PATH_MAN, "r", encoding="utf-8") as f:
                manuals = json.load(f)
        except Exception:
            manuals = []
    queries = pd.read_csv(PATH_Q) if PATH_Q.exists() else pd.DataFrame()
    weights = {}
    if PATH_WEIGHTS.exists():
        try:
            with open(PATH_WEIGHTS, "r", encoding="utf-8") as f:
                weights = json.load(f)
        except Exception:
            weights = {}
    return cmms, sensor, manuals, queries, weights

cmms, sensor, manuals, queries, weights = load_all()

# -----------------------------
# TOKENIZER (same as eval script)
# -----------------------------
TOKEN_RE = re.compile(r"[A-Za-z0-9\.\-\+√ó/]+")
def tokenize(text: str):
    if not isinstance(text, str): return []
    return [t.lower() for t in TOKEN_RE.findall(text)]

# -----------------------------
# Build corpora & BM25
# -----------------------------
man_docs = [(m.get("chunk_id", f"man_{i}"), tokenize(m.get("text",""))) for i,m in enumerate(manuals)]
cmms_docs = []
if not cmms.empty:
    for idx, r in cmms.iterrows():
        doc_id = r.get("log_id", None)
        if pd.isna(doc_id) or str(doc_id).strip() == "":
            doc_id = f"cmms_{int(idx)}"
        txt = " ".join([
            str(r.get("symptom_text","")),
            str(r.get("action_text","")),
            str(r.get("cause_text","")),
            str(r.get("fault_label",""))
        ])
        cmms_docs.append((doc_id, tokenize(txt)))

all_docs = man_docs + cmms_docs

class BM25:
    def __init__(self, docs, k1=1.5, b=0.75):
        self.k1, self.b = k1, b
        self.docs = docs
        self.N = len(docs)
        self.doc_len = np.array([len(t) for _,t in docs], dtype=float) if self.N>0 else np.array([])
        self.avgdl = self.doc_len.mean() if self.N else 0.0
        df = Counter()
        for _,t in docs: df.update(set(t))
        self.idf = {w: math.log((self.N - c + 0.5)/(c + 0.5) + 1.0) for w,c in df.items()}
        self.tf  = [Counter(t) for _,t in docs]

    def topk(self, query_text, k=5):
        if self.N == 0: return []
        q = tokenize(query_text)
        s = np.zeros(self.N, dtype=float)
        for qt in q:
            if qt not in self.idf: continue
            idf = self.idf[qt]
            for i in range(self.N):
                f = self.tf[i].get(qt, 0.0)
                if f == 0: continue
                denom = f + self.k1*(1 - self.b + self.b*(self.doc_len[i]/(self.avgdl + 1e-9)))
                s[i] += idf * (f*(self.k1+1)) / (denom + 1e-9)
        idx = np.argsort(-s)[:k]
        return [(self.docs[i][0], float(s[i])) for i in idx if s[i] > 0]

bm25_manuals = BM25(man_docs)
bm25_all     = BM25(all_docs)

# -----------------------------
# SENSOR kNN (cosine)
# -----------------------------
FEATURE_COLS = ["rms","kurtosis","peak_freq_hz","band_energy_2k_3k","one_x_rpm","two_x_rpm","temp_max_c"]
sensor_feat = sensor.copy()
if not sensor_feat.empty:
    for c in FEATURE_COLS:
        if c in sensor_feat.columns: sensor_feat[c] = sensor_feat[c].astype(float)
        else: sensor_feat[c] = 0.0
    X = sensor_feat[FEATURE_COLS].values
    mu = X.mean(axis=0) if len(X)>0 else np.zeros(len(FEATURE_COLS))
    sd = X.std(axis=0) + 1e-9 if len(X)>0 else np.ones(len(FEATURE_COLS))
    Xz = (X - mu) / sd
else:
    X = np.zeros((0,len(FEATURE_COLS))); mu = np.zeros(len(FEATURE_COLS)); sd = np.ones(len(FEATURE_COLS)); Xz = X

def cos_sim(a, b):
    a = np.asarray(a); b = np.asarray(b)
    denom = (np.linalg.norm(a)*np.linalg.norm(b) + 1e-12)
    return float(np.dot(a,b) / denom) if denom>0 else 0.0

fault_labels = set(sensor_feat["label"].unique().tolist()) if "label" in sensor_feat.columns else set()

def infer_label_from_query(q: str):
    ql = q.lower()
    for lbl in fault_labels:
        if lbl.replace("_"," ") in ql or lbl in ql: return lbl
    if "soft-foot" in ql or "soft foot" in ql: return "soft_foot" if "soft_foot" in fault_labels else None
    if "cavitation" in ql or "flow" in ql:     return "clogging" if "clogging" in fault_labels else None
    if "grease" in ql or "lubricat" in ql:     return "lubrication_issue" if "lubrication_issue" in fault_labels else None
    if "seal" in ql or "leak" in ql:           return "seal_wear" if "seal_wear" in fault_labels else None
    if "1x" in ql and "2x" in ql:              return "misalignment" if "misalignment" in fault_labels else None
    if "1x" in ql:                             return "unbalance" if "unbalance" in fault_labels else None
    if "bearing" in ql or "bpfi" in ql:        return "bearing_defect" if "bearing_defect" in fault_labels else None
    return None

NUM_RE_HZ  = re.compile(r"([0-9]+(?:\.[0-9]+)?)\s*(k?hz)", re.IGNORECASE)
NUM_RE_DEG = re.compile(r"([0-9]+(?:\.[0-9]+)?)\s*¬∞?c", re.IGNORECASE)

def query_to_feature_vector(q: str):
    ql = q.lower()
    v = mu.copy()
    if "1x" in ql:
        v[FEATURE_COLS.index("one_x_rpm")] = 1.0
    if "2x" in ql:
        v[FEATURE_COLS.index("two_x_rpm")] = 1.0
    m = NUM_RE_HZ.search(ql)
    if m:
        val, unit = m.groups()
        hz = float(val) * (1000.0 if unit.lower() == "khz" else 1.0)
        v[FEATURE_COLS.index("peak_freq_hz")] = hz
    m = NUM_RE_DEG.search(ql)
    if m:
        degc = float(m.group(1))
        v[FEATURE_COLS.index("temp_max_c")] = degc
    if ("bearing" in ql or "bpfi" in ql):
        idx = FEATURE_COLS.index("band_energy_2k_3k")
        v[idx] = max(mu[idx], 0.45)
    if ("cavitation" in ql or "broadband" in ql):
        idx = FEATURE_COLS.index("band_energy_2k_3k")
        v[idx] = mu[idx] + 0.2
    if ("misalignment" in ql or "2x" in ql):
        v[FEATURE_COLS.index("rms")] = mu[0] + 0.08
    if ("unbalance" in ql or ("1x" in ql and "2x" not in ql)):
        v[FEATURE_COLS.index("rms")] = mu[0] + 0.06
    if ("grease" in ql or "lubricat" in ql):
        v[FEATURE_COLS.index("temp_max_c")] = max(mu[-1], 80.0)
    return (v - mu) / sd

def sensor_retrieve_knn(query_text: str, k=10, label_bonus=0.15):
    if len(Xz)==0: return []
    qv = query_to_feature_vector(query_text)
    sims = np.apply_along_axis(lambda x: cos_sim(x, qv), 1, Xz)
    lbl = infer_label_from_query(query_text)
    if lbl is not None and "label" in sensor_feat.columns:
        sims = sims + (sensor_feat["label"].eq(lbl).astype(float) * label_bonus).values
    idx = np.argsort(-sims)[:k]
    out = []
    for i in idx:
        sid = sensor_feat.iloc[i].get("sensor_id", f"S{i}")
        out.append((sid, float(sims[i])))
    return out

# -----------------------------
# Symptom clues & rules
# -----------------------------
CLUE_RE_LIST = [
    r"\b1x\b", r"\b2x\b", r"\bpeak\b", r"\bhz\b", r"\bkhz\b",
    r"\brpm\b", r"\btemp\b", r"‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥", r"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", r"‡∏Ñ‡πà‡∏≤\s*rms", r"\bkurtosis\b"
]
CLUE_RE = re.compile("|".join(CLUE_RE_LIST), re.IGNORECASE)

def has_sensor_clues(q: str) -> bool:
    if not isinstance(q, str) or not q.strip():
        return False
    return bool(CLUE_RE.search(q))

SYMPTOM_RULES = [
    (re.compile(r"(‡πÑ‡∏°‡πà.*‡πÑ‡∏´‡∏•|‡∏ô‡πâ‡∏≥‡πÑ‡∏°‡πà.*‡πÑ‡∏´‡∏•|flow\s*(low|drop)|‡πÅ‡∏£‡∏á‡∏î‡∏±‡∏ô(‡∏ï‡∏Å|‡∏ï‡πà‡∏≥))", re.I), "clogging"),
    (re.compile(r"(‡∏Ñ‡∏≤‡∏ß‡∏¥‡πÄ‡∏ó‡∏ä|cavitat|‡∏ï‡∏∞‡πÅ‡∏Å‡∏£‡∏á|‡∏ß‡∏≤‡∏•‡πå‡∏ß.*(‡∏õ‡∏¥‡∏î|‡∏≠‡∏±‡πâ‡∏ô))", re.I), "clogging"),
    (re.compile(r"(‡∏ô‡πâ‡∏≥.*(‡∏£‡∏±‡πà‡∏ß|‡∏ã‡∏∂‡∏°)|‡∏ã‡∏µ‡∏•|packing|seal)", re.I), "seal_wear"),
    (re.compile(r"(‡∏£‡πâ‡∏≠‡∏ô|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á|‡∏à‡∏≤‡∏£‡∏∞‡∏ö‡∏µ|‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô)", re.I), "lubrication_issue"),
    (re.compile(r"(‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô|‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î|trip|‡πÄ‡∏ö‡∏£‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå|‡∏ü‡∏¥‡∏ß‡∏™‡πå)", re.I), "not_running"),
    (re.compile(r"(‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á|‡∏™‡∏±‡πà‡∏ô‡πÅ‡∏£‡∏á|‡πÑ‡∏ß‡πÄ‡∏ö‡∏£‡∏ä‡∏±‡∏ô‡∏™‡∏π‡∏á)", re.I), "unbalance"),
]
def guess_label_from_symptom(q: str) -> str | None:
    for pat, lbl in SYMPTOM_RULES:
        if pat.search(q or ""):
            return lbl
    if re.search(r"(alignment|‡πÅ‡∏ô‡∏ß‡πÄ‡∏û‡∏•‡∏≤|‡∏ï‡∏±‡πâ‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå)", re.I):
        return "misalignment"
    return None

# -----------------------------
# Task categorization
# -----------------------------
def categorize(q):
    ql = q.lower()
    if "root cause" in ql or "one-pass fix" in ql or "abnormal condition" in ql:
        return "diagnosis"
    if "alignment offset" in ql or "angular limits" in ql or "provide page/section" in ql:
        return "parameter_lookup"
    if "soft-foot test" in ql or "list the soft-foot" in ql or "steps" in ql:
        return "procedure"
    return "diagnosis"

def znormalize(arr):
    arr = np.array(arr, dtype=float)
    return (arr - arr.mean())/(arr.std()+1e-9) if len(arr)>0 else arr

def fuse_results(query_text, w_text, w_sensor, k=5):
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å: ‡∏õ‡∏¥‡∏î sensor ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡πÉ‡∏ö‡πâ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì
    use_sensor = has_sensor_clues(query_text) and len(Xz) > 0
    wt_eff = float(w_text)
    ws_eff = float(w_sensor) if use_sensor else 0.0

    t = bm25_all.topk(query_text, k=10)
    s = sensor_retrieve_knn(query_text, k=10) if use_sensor else []

    t_ids, t_scores = zip(*t) if t else ([],[])
    s_ids, s_scores = zip(*s) if s else ([],[])
    t_z = znormalize(list(t_scores)) if t_scores else np.array([])
    s_z = znormalize(list(s_scores)) if s_scores else np.array([])

    fused = {}
    for i, docid in enumerate(t_ids):
        fused[docid] = fused.get(docid, 0.0) + wt_eff*float(t_z[i])
    for i, sid in enumerate(s_ids):
        fused[sid] = fused.get(sid, 0.0) + ws_eff*float(s_z[i])

    ranked = sorted(fused.items(), key=lambda x: -x[1])[:k]
    return ranked, dict(t), dict(s), {"use_sensor": use_sensor, "wt_eff": wt_eff, "ws_eff": ws_eff}

# =========================
# RESULT EXPLANATION (Rule-based TH/EN)
# =========================
LABEL_EXPLANATIONS = {
    "misalignment": {
        "th": {
            "title": "‡πÅ‡∏ô‡∏ß‡πÄ‡∏û‡∏•‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á (Misalignment)",
            "desc": "‡∏û‡∏ö‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏ô‡πÅ‡∏ö‡∏ö 1√ó ‡πÅ‡∏•‡∏∞ 2√ó RPM ‡πÄ‡∏î‡πà‡∏ô ‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏û‡∏•‡∏≤/‡∏Ñ‡∏±‡∏õ‡∏õ‡∏•‡∏¥‡∏á‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ê‡∏≤‡∏ô‡∏¢‡∏∂‡∏î‡∏Ñ‡∏•‡∏≤‡∏¢",
            "checks": [
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ï‡∏±‡πâ‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏û‡∏•‡∏≤ (laser alignment/ dial gauge)",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏±‡∏õ‡∏õ‡∏•‡∏¥‡∏á‡∏™‡∏∂‡∏Å/‡∏¢‡∏∏‡∏ö/‡∏Ç‡∏±‡∏ô‡πÅ‡∏ô‡πà‡∏ô",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ê‡∏≤‡∏ô‡∏¢‡∏∂‡∏î ‡πÅ‡∏ú‡πà‡∏ô‡∏ä‡∏¥‡∏° ‡πÅ‡∏•‡∏∞ soft-foot"
            ]
        },
        "en": {
            "title": "Shaft Misalignment",
            "desc": "Dominant 1√ó and 2√ó components suggest angular/parallel misalignment or loose mounting.",
            "checks": [
                "Perform laser/dial alignment check",
                "Inspect coupling wear and fastener tightness",
                "Check base flatness and soft-foot"
            ]
        }
    },
    "unbalance": {
        "th": {
            "title": "‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏• (Unbalance)",
            "desc": "‡∏û‡∏ö 1√ó RPM ‡πÄ‡∏î‡πà‡∏ô ‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏°‡∏ß‡∏•‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô",
            "checks": [
                "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏ß‡∏á‡∏™‡∏°‡∏î‡∏∏‡∏• (balancing)",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô/‡∏Ñ‡∏£‡∏≤‡∏ö‡πÄ‡∏Å‡∏≤‡∏∞‡∏ö‡∏ô‡πÉ‡∏ö‡∏û‡∏±‡∏î",
                "‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏•‡∏≤‡∏á‡∏≠/‡πÉ‡∏ö‡∏û‡∏±‡∏î‡∏ö‡∏¥‡∏î"
            ]
        },
        "en": {
            "title": "Rotor Unbalance",
            "desc": "Dominant 1√ó component indicates mass eccentricity.",
            "checks": [
                "Dynamic balancing",
                "Clean deposits on impeller/rotor",
                "Check bent shaft or blade deformation"
            ]
        }
    },
    "bearing_defect": {
        "th": {
            "title": "‡∏ï‡∏•‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏õ‡∏∑‡∏ô‡∏°‡∏µ‡∏£‡∏≠‡∏¢‡∏ä‡∏≥‡∏£‡∏∏‡∏î (Bearing Defect)",
            "desc": "‡∏°‡∏µ broadband/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ BPFI/BPFO/BSF/FTF ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤ temp ‡∏≠‡∏≤‡∏à‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô",
            "checks": [
                "‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏‡∏à‡∏≤‡∏£‡∏∞‡∏ö‡∏µ",
                "‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏•‡∏¢‡πå/‡∏´‡∏•‡∏ß‡∏° ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥",
                "‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏•‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏õ‡∏∑‡∏ô"
            ]
        },
        "en": {
            "title": "Rolling Bearing Fault",
            "desc": "Broadband energy and bearing characteristic frequencies (BPFI/BPFO/BSF/FTF) with possible temp rise.",
            "checks": [
                "Verify lubrication schedule/grease condition",
                "Check clearance/noise",
                "Plan bearing replacement"
            ]
        }
    },
    "lubrication_issue": {
        "th": {
            "title": "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô",
            "desc": "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á/‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏à‡∏≤‡∏£‡∏∞‡∏ö‡∏µ‡πÄ‡∏™‡∏∑‡πà‡∏≠‡∏°/‡πÉ‡∏™‡πà‡∏°‡∏≤‡∏Å‡πÑ‡∏õ/‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ",
            "checks": [
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ä‡∏ô‡∏¥‡∏î/‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏à‡∏≤‡∏£‡∏∞‡∏ö‡∏µ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡πÄ‡∏õ‡∏Ñ",
                "‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡∏à‡∏≤‡∏£‡∏∞‡∏ö‡∏µ",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ã‡∏µ‡∏•‡∏£‡∏±‡πà‡∏ß‡∏ã‡∏∂‡∏°"
            ]
        },
        "en": {
            "title": "Lubrication Issue",
            "desc": "Elevated temperature and vibration; grease degradation or improper fill.",
            "checks": [
                "Verify grease type/quantity per spec",
                "Adjust regreasing interval",
                "Inspect seal leakage"
            ]
        }
    },
    "seal_wear": {
        "th": {
            "title": "‡∏ã‡∏µ‡∏•‡∏™‡∏∂‡∏Å/‡∏£‡∏±‡πà‡∏ß (Seal Wear/Leak)",
            "desc": "‡∏û‡∏ö‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á/‡∏Å‡∏≤‡∏£‡∏£‡∏±‡πà‡∏ß‡∏ã‡∏∂‡∏° ‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏õ‡∏±‡πä‡∏°‡∏•‡∏î‡∏•‡∏á",
            "checks": [
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ã‡∏µ‡∏•‡πÄ‡∏û‡∏•‡∏≤/‡πÅ‡∏û‡πá‡∏Å‡∏Å‡∏¥‡πâ‡∏á",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏£‡∏≠‡∏¢‡∏£‡∏±‡πà‡∏ß‡πÅ‡∏•‡∏∞‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏ß",
                "‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ã‡∏µ‡∏•"
            ]
        },
        "en": {
            "title": "Seal Wear / Leakage",
            "desc": "Seal degradation leads to leakage and reduced efficiency.",
            "checks": [
                "Inspect shaft seal/packing",
                "Check traces of fluid leakage",
                "Plan seal replacement"
            ]
        }
    },
    "clogging": {
        "th": {
            "title": "‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô/‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î (Clogging/Cavitation-like)",
            "desc": "‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏π‡∏á (2‚Äì3 kHz) ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏ï‡∏Å ‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≤‡∏ß‡∏¥‡πÄ‡∏ó‡∏ä‡∏±‡∏ô",
            "checks": [
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ï‡∏∞‡πÅ‡∏Å‡∏£‡∏á/‡∏ó‡πà‡∏≠‡∏î‡∏π‡∏î-‡∏à‡πà‡∏≤‡∏¢ ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏°",
                "‡∏ï‡∏£‡∏ß‡∏à NPSH/‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏ß",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏≤‡∏•‡πå‡∏ß‡∏≠‡∏±‡πâ‡∏ô/‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡πà‡∏™‡∏∏‡∏î"
            ]
        },
        "en": {
            "title": "Clogging / Cavitation-like",
            "desc": "Elevated high-band energy and flow drop suggest blockage or cavitation.",
            "checks": [
                "Check strainers/suction-discharge lines",
                "Verify NPSH/level",
                "Inspect throttling valves"
            ]
        }
    },
    "soft_foot": {
        "th": {
            "title": "Soft-foot (‡∏ê‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏°‡∏≠)",
            "desc": "‡∏ê‡∏≤‡∏ô‡∏ß‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö ‡∏ó‡∏≥‡πÉ‡∏´‡πâ alignment ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô/‡∏™‡∏±‡πà‡∏ô‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥",
            "checks": [
                "‡∏ó‡∏≥ soft-foot test ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡πà‡∏ô‡∏ä‡∏¥‡∏°",
                "‡∏Ç‡∏±‡∏ô‡∏ô‡πá‡∏≠‡∏ï‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡πÅ‡∏£‡∏á‡∏ö‡∏¥‡∏î",
                "‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô"
            ]
        },
        "en": {
            "title": "Soft-foot",
            "desc": "Base flatness issues distort alignment and elevate vibration.",
            "checks": [
                "Perform soft-foot test and shim correction",
                "Torque base bolts correctly",
                "Check base flatness"
            ]
        }
    }
}

def explain_labels_from_results(fused_rank, sensor_df, lang="th", top_n=2):
    if sensor_df is None or sensor_df.empty:
        return []
    counts = {}
    for rid, _ in fused_rank:
        if "sensor_id" in sensor_df.columns:
            m = sensor_df[sensor_df["sensor_id"].astype(str) == str(rid)]
            if not m.empty and "label" in m.columns:
                lbl = str(m.iloc[0]["label"])
                counts[lbl] = counts.get(lbl, 0) + 1
    ranked = sorted(counts.items(), key=lambda x: -x[1])[:top_n]
    explanations = []
    for lbl, _ in ranked:
        info = LABEL_EXPLANATIONS.get(lbl)
        if not info: continue
        pack = info.get(lang, info.get("th"))
        explanations.append({"label": lbl, "title": pack["title"], "desc": pack["desc"], "checks": pack["checks"]})
    return explanations

# -----------------------------
# Free AI ‚Äî polish rule-based into operator-friendly bullets
# -----------------------------
def _rule_based_operator_summary(query_text, fused_rank, sensor_df, lang="th"):
    exps = explain_labels_from_results(fused_rank, sensor_df, lang=lang, top_n=1)

    if not exps:
        # fallback ‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        lbl_sym = guess_label_from_symptom(query_text)
        if lbl_sym and lbl_sym in LABEL_EXPLANATIONS:
            pack = LABEL_EXPLANATIONS[lbl_sym].get(lang, LABEL_EXPLANATIONS[lbl_sym]["th"])
            exps = [{"label": lbl_sym, "title": pack["title"], "desc": pack["desc"], "checks": pack["checks"]}]
        elif lbl_sym == "not_running":
            if lang == "th":
                return ("‚Ä¢ ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ: ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü/‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏•‡πá‡∏≠‡∏Å‡∏ï‡∏±‡∏î ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢‡πÑ‡∏ü‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î\n"
                        "‚Ä¢ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à: ‡πÄ‡∏ö‡∏£‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå/‡∏ü‡∏¥‡∏ß‡∏™‡πå/‡πÇ‡∏≠‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÇ‡∏´‡∏•‡∏î ‚Ä¢ ‡∏õ‡∏∏‡πà‡∏°‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô/‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô/‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏•‡πá‡∏≠‡∏Å ‚Ä¢ ‡∏Ñ‡∏±‡∏õ‡∏õ‡∏•‡∏¥‡∏á‡∏´‡∏•‡∏∏‡∏î/‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ñ‡πâ‡∏≤‡∏á\n"
                        "‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå trip ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏ï‡∏£‡∏ß‡∏à‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô‡∏≠‡∏¥‡∏™‡∏£‡∏∞‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÉ‡∏´‡∏°‡πà\n"
                        "‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏ó‡∏≥ LOTO ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏â‡∏ô‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏ü‡πâ‡∏≤")
            else:
                return ("‚Ä¢ Probable causes: power/interlock trips or drive seizure\n"
                        "‚Ä¢ Checks: breaker/fuse/overload ‚Ä¢ E-stop/pressure switch/guard interlock ‚Ä¢ coupling/motor free\n"
                        "‚Ä¢ Quick fixes: clear trips, reset, ensure free rotation before restart\n"
                        "‚Ä¢ Safety: LOTO and electrical safety")

    if exps:
        e = exps[0]
        if lang == "th":
            return (f"‚Ä¢ ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ: {e['title']}\n"
                    f"‚Ä¢ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à: " + " ; ".join(e["checks"][:3]) + "\n"
                    f"‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡πâ‡∏á/‡∏Ç‡∏±‡∏ô‡πÅ‡∏ô‡πà‡∏ô/‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏™‡πÄ‡∏õ‡∏Å\n"
                    f"‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏õ‡∏¥‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ LOTO ‡∏Å‡πà‡∏≠‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
        else:
            return (f"‚Ä¢ Probable causes: {e['title']}\n"
                    f"‚Ä¢ Checks: " + " ; ".join(e["checks"][:3]) + "\n"
                    f"‚Ä¢ Quick fixes: re-align/tighten/lubricate per spec\n"
                    f"‚Ä¢ Safety: LOTO before any work")

    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢
    if lang == "th":
        return ("‚Ä¢ ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ: ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏•‡∏≤/‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•/‡πÅ‡∏£‡∏á‡∏î‡∏±‡∏ô/‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô\n"
                "‚Ä¢ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à: 1√ó/2√ó, ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏õ‡∏•‡∏≤‡∏¢‡πÄ‡∏û‡∏•‡∏≤, ‡∏Ñ‡∏±‡∏õ‡∏õ‡∏•‡∏¥‡∏á, ‡∏ã‡∏µ‡∏•, ‡πÅ‡∏ö‡∏£‡∏¥‡πà‡∏á\n"
                "‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡∏ï‡∏±‡πâ‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå/‡∏Ç‡∏±‡∏ô‡πÅ‡∏ô‡πà‡∏ô/‡∏õ‡∏£‡∏±‡∏ö‡∏´‡∏•‡πà‡∏≠‡∏•‡∏∑‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏™‡πÄ‡∏õ‡∏Å\n"
                "‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏õ‡∏¥‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ LOTO ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    else:
        return ("‚Ä¢ Probable causes: shaft/flow/pressure/lubrication issues\n"
                "‚Ä¢ Checks: 1√ó/2√ó, shaft temp, coupling, seal, bearing\n"
                "‚Ä¢ Quick fixes: re-align, tighten, lubricate per spec\n"
                "‚Ä¢ Safety: LOTO before work")

@st.cache_resource(show_spinner=False)
def load_hf_pipeline(model_name: str, max_new_tokens: int = 80):
    from transformers import pipeline
    task = "text2text-generation" if any(k in model_name.lower() for k in ["flan","t5","ul2"]) else "text-generation"
    gen = pipeline(
        task=task,
        model=model_name,
        device_map="auto",
        max_new_tokens=max_new_tokens,
        do_sample=False,
        temperature=0.0,
        top_p=1.0,
        repetition_penalty=1.05,
        truncation=True,
        pad_token_id=0,
    )
    return gen

def ai_explain_free_hf(query_text, fused_rank, manuals, cmms, sensor_df, model_name, lang_code="th"):
    # 1) ‡∏ó‡∏≥‡∏£‡πà‡∏≤‡∏á 4 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏ö‡∏ö‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
    draft = _rule_based_operator_summary(query_text, fused_rank, sensor_df, lang=lang_code)

    # 2) ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Äú‡∏£‡∏µ‡πÑ‡∏£‡∏ï‡πå‚Äù ‡πÇ‡∏î‡∏¢‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
    if lang_code == "th":
        polish_prompt = (
            "‡πÇ‡∏õ‡∏£‡∏î‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ä‡πà‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏á‡∏≤‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á 4 ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πä‡∏∞ "
            "(‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà)\n\n"
            "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:\n"
            "‚Ä¢ ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ: ‚Ä¶\n"
            "‚Ä¢ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à: ‚Ä¶\n"
            "‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‚Ä¶\n"
            "‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‚Ä¶\n\n"
            f"{draft}"
        )
    else:
        polish_prompt = (
            "Rewrite the following into clear field-tech bullets keeping EXACTLY these 4 headings "
            "(do not add new facts):\n"
            "‚Ä¢ Probable causes: ‚Ä¶\n"
            "‚Ä¢ Checks: ‚Ä¶\n"
            "‚Ä¢ Quick fixes: ‚Ä¶\n"
            "‚Ä¢ Safety: ‚Ä¶\n\n"
            f"{draft}"
        )

    try:
        gen = load_hf_pipeline(model_name=model_name, max_new_tokens=80)
        out = gen(polish_prompt)
        text = out[0].get("generated_text","").strip()

        # clean: ‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‚Ä¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 4 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        cleaned = []
        for ln in lines:
            if ln.startswith("- "): ln = "‚Ä¢ " + ln[2:].strip()
            if not ln.startswith("‚Ä¢"): ln = "‚Ä¢ " + ln
            cleaned.append(ln)
            if len(cleaned) >= 4: break
        if len(cleaned) < 4:
            return draft
        return "\n".join(cleaned)
    except Exception:
        return draft

# -----------------------------
# UI
# -----------------------------
st.title("ü§ñ FactoryRAG-TAF ‚Äî Chat & Expert Evaluation")

# Sidebar: Evaluator
st.sidebar.header("üë©‚Äçüè≠ Evaluator")
evaluator_code = st.sidebar.text_input("Evaluator code (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏Æ‡∏ä, ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á)", "")
role = st.sidebar.selectbox("Role", ["Maintenance Engineer","Process Engineer","Safety Officer","Operator","Other"])
years = st.sidebar.number_input("Years of experience", 0, 50, 5)
domain = st.sidebar.text_input("Factory domain", "Sugar Mill")

# Sidebar: Retrieval Settings
st.sidebar.header("‚öôÔ∏è Retrieval Settings")
task_mode = st.sidebar.selectbox("Task", ["auto","diagnosis","parameter_lookup","procedure"], index=0)

default_wt = 0.7; default_ws = 0.3  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ô‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÄ‡∏£‡πá‡∏ß+‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
if weights: st.sidebar.info("Loaded task-aware weights from file.")
else:       st.sidebar.warning("No task_aware_best_weights.json found ‚Äî using manual sliders below.")

if task_mode != "auto" and weights.get(task_mode):
    default_wt = float(weights[task_mode].get("w_text", default_wt))
    default_ws = float(weights[task_mode].get("w_sensor", default_ws))

w_text = st.sidebar.slider("Weight: Text", 0.0, 1.0, default_wt, 0.05)
w_sensor = st.sidebar.slider("Weight: Sensor", 0.0, 1.0, default_ws, 0.05)
top_k = st.sidebar.slider("Top-K", 3, 10, 5)

# Sidebar: Explanation
st.sidebar.header("üß† Explanation")
lang_choice = st.sidebar.radio("Language / ‡∏†‡∏≤‡∏©‡∏≤", ["‡πÑ‡∏ó‡∏¢", "English"], index=0, horizontal=True)
lang_code = "th" if lang_choice == "‡πÑ‡∏ó‡∏¢" else "en"

# Sidebar: Free AI (HF)
st.sidebar.header("ü§ñ Free AI (Hugging Face)")
use_hf_ai = st.sidebar.toggle("Use Free AI (HF)", value=False, help="‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ (‡πÄ‡∏ô‡πâ‡∏ô‡∏™‡∏±‡πâ‡∏ô/‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)")
model_name = st.sidebar.selectbox(
    "Model (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å‡∏ö‡∏ô CPU)",
    [
        "google/flan-t5-small",                 # ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å‡∏ö‡∏ô CPU (default)
        "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "Qwen/Qwen2.5-1.5B-Instruct",
        "microsoft/Phi-3-mini-4k-instruct"      # ‡∏ä‡πâ‡∏≤‡∏ö‡∏ô CPU
    ],
    index=0
)

# Main input
query_default = (queries["query_text"].iloc[0] if ("query_text" in queries.columns and len(queries)>0) else "")
query = st.text_area("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:", value=query_default, height=120,
                     placeholder="‡πÄ‡∏ä‡πà‡∏ô '‡∏õ‡∏±‡πä‡∏°‡∏õ‡πâ‡∏≠‡∏ô‡∏ô‡πâ‡∏≥‡∏≠‡πâ‡∏≠‡∏¢‡∏™‡∏±‡πà‡∏ô‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á PM ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏≠‡∏∞‡πÑ‡∏£'")
run = st.button("üîé Run")

if run and query.strip():
    # determine task
    task = categorize(query) if task_mode == "auto" else task_mode

    # weights
    if weights.get(task):
        wt = float(weights[task].get("w_text", w_text))
        ws = float(weights[task].get("w_sensor", w_sensor))
    else:
        wt, ws = w_text, w_sensor

    t0 = time.time()
    fused_rank, text_dict, sensor_dict, wtinfo = fuse_results(query, wt, ws, k=top_k)
    latency_ms = int((time.time() - t0)*1000)

    st.subheader(f"üìå Task = **{task}**  |  Weights: text={wtinfo['wt_eff']:.2f}, sensor={wtinfo['ws_eff']:.2f}  |  Latency: {latency_ms} ms")
    if not wtinfo["use_sensor"]:
        st.caption("‚ÑπÔ∏è ‡∏õ‡∏¥‡∏î‡∏ù‡∏±‡πà‡∏á sensor ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡πÉ‡∏ö‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì (1√ó/2√ó, Hz, ¬∞C ‡∏Ø‡∏•‡∏Ø)")

    # Display fused ranking with provenance
    st.markdown("### üîó Top Results (Fused)")
    for rank, (rid, score) in enumerate(fused_rank, start=1):
        src = None; detail = None
        # manual
        if any(rid == m.get("chunk_id") for m in manuals):
            m = next(m for m in manuals if m.get("chunk_id")==rid)
            src = f"Manual: {m.get('doc')} (sec {m.get('section')}, pages {m.get('pages')})"
            detail = m.get("text","")
        # cmms
        if src is None and not cmms.empty:
            match = cmms[cmms["log_id"].astype(str) == str(rid)] if "log_id" in cmms.columns else pd.DataFrame()
            if not match.empty:
                row = match.iloc[0]
                src = f"CMMS log #{row.get('log_id')}"
                detail = " | ".join([str(row.get("symptom_text","")), str(row.get("action_text","")), str(row.get("cause_text",""))])
        # sensor
        if src is None and not sensor_feat.empty:
            match = sensor_feat[sensor_feat["sensor_id"].astype(str) == str(rid)] if "sensor_id" in sensor_feat.columns else pd.DataFrame()
            if not match.empty:
                row = match.iloc[0]
                src = f"Sensor #{row.get('sensor_id')} (label={row.get('label','-')})"
                vals = ", ".join([f"{c}={row.get(c)}" for c in ["rms","kurtosis","peak_freq_hz","band_energy_2k_3k","one_x_rpm","two_x_rpm","temp_max_c"] if c in row])
                detail = vals

        tsc = text_dict.get(rid, None)
        ssc = sensor_dict.get(rid, None)

        with st.expander(f"{rank}. {rid}  |  fused={score:.3f}  (text={tsc if tsc is not None else '-'}, sensor={ssc if ssc is not None else '-'})", expanded=False):
            if src: st.markdown(f"**Source:** {src}")
            if detail: st.write(detail)
            if src and src.startswith("Manual"):
                md = next(m for m in manuals if m.get("chunk_id")==rid)
                st.caption(f"Doc={md.get('doc')} | Section={md.get('section')} | Pages={md.get('pages')}")

    # --- Rule-based Explanation ---
    st.markdown("---")
    st.markdown("### üß† Result Explanation (Rule-based)")
    exps = explain_labels_from_results(fused_rank, sensor_feat, lang=lang_code, top_n=2)
    if not exps:
        # ‡πÇ‡∏ä‡∏ß‡πå‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ sensor label
        lbl_sym = guess_label_from_symptom(query)
        if lbl_sym and lbl_sym in LABEL_EXPLANATIONS:
            pack = LABEL_EXPLANATIONS[lbl_sym].get(lang_code, LABEL_EXPLANATIONS[lbl_sym]["th"])
            exps = [{"label": lbl_sym, "title": pack["title"], "desc": pack["desc"], "checks": pack["checks"]}]
        elif lbl_sym == "not_running":
            if lang_code == "th":
                st.markdown("**‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô / ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î**")
                st.write("‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡πÅ‡∏•‡∏∞ interlock ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á")
                st.markdown("- **‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à:**")
                for c in ["‡∏ï‡∏£‡∏ß‡∏à‡πÑ‡∏ü‡∏´‡∏•‡∏±‡∏Å/‡πÄ‡∏ö‡∏£‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå/‡∏ü‡∏¥‡∏ß‡∏™‡πå/‡πÇ‡∏≠‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÇ‡∏´‡∏•‡∏î", "‡∏õ‡∏∏‡πà‡∏°‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô/‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô/‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏•‡πá‡∏≠‡∏Å", "‡∏Ñ‡∏±‡∏õ‡∏õ‡∏•‡∏¥‡∏á‡∏´‡∏•‡∏∏‡∏î/‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î"]:
                    st.markdown(f"  - {c}")
            else:
                st.markdown("**Pump not running / cannot start**")
                st.write("Check electrical supply and interlocks before mechanical work.")
                st.markdown("- **Checks:**")
                for c in ["Main breaker/fuse/overload", "E-stop/pressure switch/guard interlock", "Coupling shear/loose, motor seized"]:
                    st.markdown(f"  - {c}")

    if exps:
        for e in exps:
            st.markdown(f"**{e['title']}**")
            st.write(e["desc"])
            st.markdown("- **‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à:**" if lang_code == "th" else "- **Recommended checks:**")
            for c in e["checks"]: st.markdown(f"  - {c}")
            st.markdown("")
    elif not exps and lang_code != "th":
        st.caption("No clear sensor-based evidence to summarize.")

    # --- Free AI Explanation (HF) ---
    if use_hf_ai:
        st.markdown("### ü§ñ Result Explanation (Free AI ‚Äî Hugging Face)")
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ü‡∏£‡∏µ: {model_name} ..."):
            ai_text = ai_explain_free_hf(query, fused_rank, manuals, cmms, sensor_feat, model_name=model_name, lang_code=lang_code)
        st.markdown(ai_text if ai_text else "_‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ü‡∏£‡∏µ‡πÑ‡∏î‡πâ_")

    # --- Expert rating panel
    st.markdown("---")
    st.subheader("üìù Expert Rating (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°)")
    col1, col2, col3 = st.columns(3)
    with col1:
        rated_accuracy = st.slider("Accuracy", 1, 5, 4)
        rated_completeness = st.slider("Completeness", 1, 5, 4)
        rated_groundedness = st.slider("Groundedness", 1, 5, 5)
    with col2:
        rated_helpful = st.slider("Helpfulness", 1, 5, 5)
        rated_actionable = st.slider("Actionability", 1, 5, 5)
        rated_safety = st.slider("Safety", 1, 5, 5)
    with col3:
        rated_overall = st.slider("Overall", 1, 5, 5)
        hallucination = st.checkbox("‡∏û‡∏ö Hallucination/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô", value=False)
        policy_violation = st.checkbox("‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢/‡∏ú‡∏¥‡∏î‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", value=False)

    comment = st.text_area("‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°", height=100, placeholder="‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞")
    decision = st.radio("‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (accept/reject)", ["accept","reject"], horizontal=True)

    if st.button("üíæ Save rating"):
        rater_hash = hashlib.sha1((evaluator_code or "anon").encode()).hexdigest()[:8]
        row = {
            "session_id": f"S-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "latency_ms": latency_ms,
            "rater_hash": rater_hash,
            "rater_role": role,
            "years_experience": years,
            "factory_domain": domain,
            "task": task,
            "query_text": query,
            "w_text": wtinfo['wt_eff'], "w_sensor": wtinfo['ws_eff'], "top_k": top_k,
            "rated_accuracy": rated_accuracy,
            "rated_completeness": rated_completeness,
            "rated_groundedness": rated_groundedness,
            "rated_helpfulness": rated_helpful,
            "rated_actionability": rated_actionable,
            "rated_safety": rated_safety,
            "rated_overall": rated_overall,
            "hallucination_flag": hallucination,
            "policy_violation_flag": policy_violation,
            "decision": decision,
            "comment": comment,
            "fused_ids": ";".join([rid for rid,_ in fused_rank]),
            "text_scores_json": json.dumps({k: float(v) for k,v in text_dict.items()}),
            "sensor_scores_json": json.dumps({k: float(v) for k,v in sensor_dict.items()})
        }
        try:
            if LOG_PATH.exists():
                df = pd.read_csv(LOG_PATH)
                df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
            else:
                df = pd.DataFrame([row])
            df.to_csv(LOG_PATH, index=False)
            st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‚Üí {LOG_PATH.name}")
        except Exception as e:
            st.error(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

else:
    st.info("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Run ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å manuals + CMMS + sensor ‡πÅ‡∏•‡∏∞ (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î) ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ü‡∏£‡∏µ‡∏ö‡∏ô Hugging Face")




